{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook for creating all the dependencies for the airline data we have scraped so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kengb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments shape: (43260, 7)\n",
      "posts shape: (1547, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(44807, 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from absa_model import CSV_Dataset\n",
    "import pandas as pd\n",
    "\n",
    "delta_comments = pd.read_csv('../data/combined_cleaned_delta_comments.csv')\n",
    "print(f\"comments shape: {delta_comments.shape}\")\n",
    "delta_posts = pd.read_csv('../data/combined_cleaned_delta_posts.csv')\n",
    "print(f\"posts shape: {delta_posts.shape}\")\n",
    "delta_posts['content'] = delta_posts['content'] + delta_posts['title']\n",
    "delta_df = pd.concat([delta_comments[['content']], delta_posts[['content']]], ignore_index=True)\n",
    "delta_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44010, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_df.drop_duplicates(subset=\"content\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing csv objects\n",
      "Parsed csv objects of size (41679, 1)\n",
      "Preparing dataset for ABSA...\n",
      "Preparing vectorizer...\n",
      "Vectorizer saved as delta_airlines_vectorizer.pkl\n",
      "Preparing LDA model...\n",
      "LDA model saved as delta_airlines_lda_model.pkl\n",
      "Topic dictionary saved as delta_airlines_topic_dict.pkl\n",
      "Preparing VADER model...\n",
      "VADER model saved as delta_airlines_vader_model.pkl\n",
      "Dataset prepared for ABSA\n",
      "Performing ABSA...\n",
      "Extracting aspects...\n",
      "Extracting aspects\n",
      "Getting sentiment...\n",
      "ABSA completed\n"
     ]
    }
   ],
   "source": [
    "delta_df = delta_df.drop_duplicates(subset=\"content\")\n",
    "delta = CSV_Dataset(delta_df, dataset_name='delta_airlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>separ rest famili dl want pay sit togeth inste...</td>\n",
       "      <td>\"Travel Experience with Delta\"</td>\n",
       "      <td>-0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>see side employe frustrat get famili board giv...</td>\n",
       "      <td>\"Travel Experience with Delta\"</td>\n",
       "      <td>-0.5213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id sue donat whatev didnt need daughter therap...</td>\n",
       "      <td>\"Upgrade Experience\"</td>\n",
       "      <td>-0.9022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>delta fault parent given right pick seat https...</td>\n",
       "      <td>\"Airline Seating Experience\"</td>\n",
       "      <td>-0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man fault assault victim hope ban fli proceed ...</td>\n",
       "      <td>\"Upgrade Experience\"</td>\n",
       "      <td>-0.9201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41674</th>\n",
       "      <td>minut goe delta could final loos stranglehold ...</td>\n",
       "      <td>\"Airline Seating Experience\"</td>\n",
       "      <td>0.4588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41675</th>\n",
       "      <td>anyon fisherman stew new fisherman stew</td>\n",
       "      <td>\"Travel Experience with Delta\"</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41676</th>\n",
       "      <td>fli im get delay am hr layov shower crown loun...</td>\n",
       "      <td>\"Travel Experience\"</td>\n",
       "      <td>0.6808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41677</th>\n",
       "      <td>anyon delta one tumi discount code use tumi cr...</td>\n",
       "      <td>\"Upgrade Experience\"</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41678</th>\n",
       "      <td>youv travel lot know import carryon serv immed...</td>\n",
       "      <td>\"Upgrade Experience\"</td>\n",
       "      <td>0.9628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41679 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  \\\n",
       "0      separ rest famili dl want pay sit togeth inste...   \n",
       "1      see side employe frustrat get famili board giv...   \n",
       "2      id sue donat whatev didnt need daughter therap...   \n",
       "3      delta fault parent given right pick seat https...   \n",
       "4      man fault assault victim hope ban fli proceed ...   \n",
       "...                                                  ...   \n",
       "41674  minut goe delta could final loos stranglehold ...   \n",
       "41675            anyon fisherman stew new fisherman stew   \n",
       "41676  fli im get delay am hr layov shower crown loun...   \n",
       "41677  anyon delta one tumi discount code use tumi cr...   \n",
       "41678  youv travel lot know import carryon serv immed...   \n",
       "\n",
       "                                topic  sentiment  \n",
       "0      \"Travel Experience with Delta\"    -0.4019  \n",
       "1      \"Travel Experience with Delta\"    -0.5213  \n",
       "2                \"Upgrade Experience\"    -0.9022  \n",
       "3        \"Airline Seating Experience\"    -0.4019  \n",
       "4                \"Upgrade Experience\"    -0.9201  \n",
       "...                               ...        ...  \n",
       "41674    \"Airline Seating Experience\"     0.4588  \n",
       "41675  \"Travel Experience with Delta\"     0.0000  \n",
       "41676             \"Travel Experience\"     0.6808  \n",
       "41677            \"Upgrade Experience\"     0.6369  \n",
       "41678            \"Upgrade Experience\"     0.9628  \n",
       "\n",
       "[41679 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frontier Airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments shape: (10445, 7)\n",
      "posts shape: (232, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10677, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier_comments = pd.read_csv('../data/frontierairlines_selenium_comments.csv')\n",
    "print(f\"comments shape: {frontier_comments.shape}\")\n",
    "frontier_posts = pd.read_csv('../data/frontierairlines_selenium_posts.csv')\n",
    "print(f\"posts shape: {frontier_posts.shape}\")\n",
    "frontier_posts['content'] = frontier_posts['content'] + frontier_posts['title']\n",
    "frontier_df = pd.concat([frontier_comments[['content']], frontier_posts[['content']]], ignore_index=True)\n",
    "frontier_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing csv objects\n",
      "Parsed csv objects of size (10084, 1)\n",
      "Preparing dataset for ABSA...\n",
      "Preparing vectorizer...\n",
      "Vectorizer saved as frontier_airlines_vectorizer.pkl\n",
      "Preparing LDA model...\n",
      "LDA model saved as frontier_airlines_lda_model.pkl\n",
      "Topic dictionary saved as frontier_airlines_topic_dict.pkl\n",
      "Preparing VADER model...\n",
      "VADER model saved as frontier_airlines_vader_model.pkl\n",
      "Dataset prepared for ABSA\n",
      "Performing ABSA...\n",
      "Extracting aspects...\n",
      "Extracting aspects\n",
      "Getting sentiment...\n",
      "ABSA completed\n"
     ]
    }
   ],
   "source": [
    "frontier_df = frontier_df.drop_duplicates(subset=\"content\")\n",
    "frontier = CSV_Dataset(frontier_df, dataset_name='frontier_airlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seem remark calm</td>\n",
       "      <td>\"Travel Turmoil\"</td>\n",
       "      <td>0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ultim got need go suck airport much suck deal ...</td>\n",
       "      <td>\"Flight Experience Insights\"</td>\n",
       "      <td>-0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unaccept airlin</td>\n",
       "      <td>\"Flight Experience Insights\"</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yet peopl still defend fli frontier</td>\n",
       "      <td>\"Travel Experience\"</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actual file formal complaint better busi burea...</td>\n",
       "      <td>\"Travel Turmoil\"</td>\n",
       "      <td>0.2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10079</th>\n",
       "      <td>dont fli first flight paid middl window seat s...</td>\n",
       "      <td>\"Flight Experience\"</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10080</th>\n",
       "      <td>anyon dealt frontier lose bag nonstop flight l...</td>\n",
       "      <td>\"Travel Turmoil\"</td>\n",
       "      <td>-0.9337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10081</th>\n",
       "      <td>fli home orlando easter sunday flight super ea...</td>\n",
       "      <td>\"Flight Experience\"</td>\n",
       "      <td>-0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10082</th>\n",
       "      <td>tldr frontier attend lie face amp stole power ...</td>\n",
       "      <td>\"Travel Turmoil\"</td>\n",
       "      <td>-0.9186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10083</th>\n",
       "      <td>flight philadelphia right plane readi leav gat...</td>\n",
       "      <td>\"Travel Turmoil\"</td>\n",
       "      <td>0.4767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10084 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  \\\n",
       "0                                       seem remark calm   \n",
       "1      ultim got need go suck airport much suck deal ...   \n",
       "2                                        unaccept airlin   \n",
       "3                    yet peopl still defend fli frontier   \n",
       "4      actual file formal complaint better busi burea...   \n",
       "...                                                  ...   \n",
       "10079  dont fli first flight paid middl window seat s...   \n",
       "10080  anyon dealt frontier lose bag nonstop flight l...   \n",
       "10081  fli home orlando easter sunday flight super ea...   \n",
       "10082  tldr frontier attend lie face amp stole power ...   \n",
       "10083  flight philadelphia right plane readi leav gat...   \n",
       "\n",
       "                              topic  sentiment  \n",
       "0                  \"Travel Turmoil\"     0.3182  \n",
       "1      \"Flight Experience Insights\"    -0.2500  \n",
       "2      \"Flight Experience Insights\"     0.0000  \n",
       "3               \"Travel Experience\"     0.0000  \n",
       "4                  \"Travel Turmoil\"     0.2010  \n",
       "...                             ...        ...  \n",
       "10079           \"Flight Experience\"     0.3612  \n",
       "10080              \"Travel Turmoil\"    -0.9337  \n",
       "10081           \"Flight Experience\"    -0.3818  \n",
       "10082              \"Travel Turmoil\"    -0.9186  \n",
       "10083              \"Travel Turmoil\"     0.4767  \n",
       "\n",
       "[10084 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontier.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hawaiian Airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments shape: (1523, 7)\n",
      "posts shape: (198, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1721, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hawaiian_comments = pd.read_csv('../data/HawaiianAirlines_selenium_comments.csv')\n",
    "print(f\"comments shape: {hawaiian_comments.shape}\")\n",
    "hawaiian_posts = pd.read_csv('../data/HawaiianAirlines_selenium_posts.csv')\n",
    "print(f\"posts shape: {hawaiian_posts.shape}\")\n",
    "hawaiian_posts['content'] = hawaiian_posts['content'] + hawaiian_posts['title']\n",
    "hawaiian_df = pd.concat([hawaiian_comments[['content']], hawaiian_posts[['content']]], ignore_index=True)\n",
    "hawaiian_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing csv objects\n",
      "Parsed csv objects of size (1620, 1)\n",
      "Preparing dataset for ABSA...\n",
      "Preparing vectorizer...\n",
      "Vectorizer saved as frontier_airlines_vectorizer.pkl\n",
      "Preparing LDA model...\n",
      "LDA model saved as frontier_airlines_lda_model.pkl\n",
      "Topic dictionary saved as frontier_airlines_topic_dict.pkl\n",
      "Preparing VADER model...\n",
      "VADER model saved as frontier_airlines_vader_model.pkl\n",
      "Dataset prepared for ABSA\n",
      "Performing ABSA...\n",
      "Extracting aspects...\n",
      "Extracting aspects\n",
      "Getting sentiment...\n",
      "ABSA completed\n"
     ]
    }
   ],
   "source": [
    "hawaiian_df = hawaiian_df.drop_duplicates(subset=\"content\")\n",
    "hawaii = CSV_Dataset(hawaiian_df, dataset_name='frontier_airlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeah look one</td>\n",
       "      <td>Topic: \"Aloha Travel Experience\"</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clariti referr code fa write credit card appli...</td>\n",
       "      <td>\"Flight Experience Enhancement\"</td>\n",
       "      <td>0.7003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get code</td>\n",
       "      <td>\"Travel Essentials Experience\"</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hope code well thank advanc</td>\n",
       "      <td>\"Upgrade Odyssey\"</td>\n",
       "      <td>0.7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>could dm plz</td>\n",
       "      <td>\"Flight Experience Enhancement\"</td>\n",
       "      <td>0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>hello fli hnl san stop maui next wednesday ret...</td>\n",
       "      <td>\"Upgrade Experience\"</td>\n",
       "      <td>-0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>hey anyon jfkhnl late wonder wifi avail thanks...</td>\n",
       "      <td>\"Travel Essentials Experience\"</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>seatgurucom doesnt ha yet advic row avoid look...</td>\n",
       "      <td>\"Travel Essentials Experience\"</td>\n",
       "      <td>-0.4471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>flight tokyo almost hour layov hnl fli ny id l...</td>\n",
       "      <td>\"Upgrade Experience\"</td>\n",
       "      <td>0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>may took flight kiosk print bag tag line guest...</td>\n",
       "      <td>\"Flight Experience Enhancement\"</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1620 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  \\\n",
       "0                                         yeah look one   \n",
       "1     clariti referr code fa write credit card appli...   \n",
       "2                                              get code   \n",
       "3                           hope code well thank advanc   \n",
       "4                                          could dm plz   \n",
       "...                                                 ...   \n",
       "1615  hello fli hnl san stop maui next wednesday ret...   \n",
       "1616  hey anyon jfkhnl late wonder wifi avail thanks...   \n",
       "1617  seatgurucom doesnt ha yet advic row avoid look...   \n",
       "1618  flight tokyo almost hour layov hnl fli ny id l...   \n",
       "1619  may took flight kiosk print bag tag line guest...   \n",
       "\n",
       "                                 topic  sentiment  \n",
       "0     Topic: \"Aloha Travel Experience\"     0.2960  \n",
       "1      \"Flight Experience Enhancement\"     0.7003  \n",
       "2       \"Travel Essentials Experience\"     0.0000  \n",
       "3                    \"Upgrade Odyssey\"     0.7579  \n",
       "4      \"Flight Experience Enhancement\"     0.0772  \n",
       "...                                ...        ...  \n",
       "1615              \"Upgrade Experience\"    -0.3400  \n",
       "1616    \"Travel Essentials Experience\"     0.0000  \n",
       "1617    \"Travel Essentials Experience\"    -0.4471  \n",
       "1618              \"Upgrade Experience\"     0.3818  \n",
       "1619   \"Flight Experience Enhancement\"     0.4215  \n",
       "\n",
       "[1620 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hawaii.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
